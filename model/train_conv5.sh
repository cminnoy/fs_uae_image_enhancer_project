#!/bin/bash
python train.py --model_type conv5 --epochs  20 --batch_size 16 --accumulation_steps  1 --learning_rate 0.0006 --checkpoint_interval 5  --generator_train_dir $HOME/project/datasets/dataset_combined_enhancer2 --train_samples 5000 --val_samples 500 --val_split_ratio 0.1 --crop_size 376 288 --checkpoint_dir model_conv5 --early_stopping_patience 10
python train.py --model_type conv5 --epochs  40 --batch_size 32 --accumulation_steps  1 --learning_rate 0.0006 --checkpoint_interval 5  --generator_train_dir $HOME/project/datasets/dataset_combined_enhancer2 --train_samples 6000 --val_samples 600 --val_split_ratio 0.1 --crop_size 376 288 --checkpoint_dir model_conv5 --early_stopping_patience 15
python train.py --model_type conv5 --epochs  80 --batch_size 32 --accumulation_steps  2 --learning_rate 0.0006 --checkpoint_interval 5  --generator_train_dir $HOME/project/datasets/dataset_combined_enhancer2 --train_samples 7000 --val_samples 700 --val_split_ratio 0.1 --crop_size 376 288 --checkpoint_dir model_conv5 --early_stopping_patience 20
python train.py --model_type conv5 --epochs 120 --batch_size 32 --accumulation_steps  4 --learning_rate 0.0006 --checkpoint_interval 5  --generator_train_dir $HOME/project/datasets/dataset_combined_enhancer2 --train_samples 8000 --val_samples 800 --val_split_ratio 0.1 --crop_size 376 288 --checkpoint_dir model_conv5 --early_stopping_patience 25
python train.py --model_type conv5 --epochs 200 --batch_size 32 --accumulation_steps  8 --learning_rate 0.0006 --checkpoint_interval 5  --generator_train_dir $HOME/project/datasets/dataset_combined_enhancer2 --train_samples 9000 --val_samples 900 --val_split_ratio 0.1 --crop_size 376 288 --checkpoint_dir model_conv5 --early_stopping_patience 30
